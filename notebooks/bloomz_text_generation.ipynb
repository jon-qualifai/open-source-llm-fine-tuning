{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "662f17dd",
   "metadata": {},
   "source": [
    "# Bloomz - Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d06bde",
   "metadata": {},
   "source": [
    "## Fine Tuning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcdf3c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23d458e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.abspath(os.path.join('..', 'data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17dd8e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ob-loose-jun28-sm.jsonl', 'offload_folder', 'huggingface_cache']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46e2ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(DATA_DIR, 'ob-loose-jun28-sm.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2b4d7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "with open(file_path, 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "\n",
    "for json_str in json_list:\n",
    "    result = json.loads(json_str)\n",
    "    results.append(result)\n",
    "    if not isinstance(result, dict):\n",
    "        print('JSON line could not be parsed as a dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c249aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = random.choice(results)['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62def202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rephrase and join the sentences to remove repetition and sound more human without changing the wording and semantics.\n",
      "The only exception is that you are allowed to rephrase from the user query the <|NOT_SURE|> parts.\n",
      "\n",
      "###\n",
      "\n",
      "Question: I have an inquiry about my purchase transactions, where can I send my message?\n",
      "Robotic Answer: <|NOT_SURE|> <|CryptoWallet does not offer support via telephone so for inquiries, users must send an email at support@cryptos.com.|>\n",
      "Human Answer:\n"
     ]
    }
   ],
   "source": [
    "print(example_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da96a011",
   "metadata": {},
   "source": [
    "## mt0-small - 300M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "760eb4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bigscience/mt0-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b192e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b03cfecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint, torch_dtype=\"auto\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b50b59ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> cryptos.com</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jon/anaconda3/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(example_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(inputs)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b22073",
   "metadata": {},
   "source": [
    "## mt0-base "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d315cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_base = \"bigscience/mt0-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "663a420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_base = AutoTokenizer.from_pretrained(checkpoint_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b452e9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_base, torch_dtype=\"auto\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad575eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = \"Explain in a sentence in Spanish what is backpropagation in neural networks.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "413af87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Qué es la propagación de datos en las redes nocturnas?</s>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer_base.encode(example_prompt, truncation=False, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model_base.generate(inputs)\n",
    "print(tokenizer_base.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b156be6e",
   "metadata": {},
   "source": [
    "## mt0-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8557bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_large = \"bigscience/mt0-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76634eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_large = AutoTokenizer.from_pretrained(checkpoint_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442e4865",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_large = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_large, torch_dtype=\"auto\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda4f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer_base.encode(example_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model_base.generate(inputs,  max_length=100)\n",
    "print(tokenizer_base.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc10656",
   "metadata": {},
   "source": [
    "## mt0-xxl - 13B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32743d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = os.path.join(DATA_DIR, 'huggingface_cache')\n",
    "try:\n",
    "    os.mkdir(CACHE_DIR)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6b837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OFFLOAD_FOLDER = os.path.join(DATA_DIR, 'offload_folder')\n",
    "try:\n",
    "    os.mkdir(OFFLOAD_FOLDER)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5688c7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "MAX_MEMORY = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd0652",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_xxl = \"bigscience/mt0-xxl\"\n",
    "\n",
    "tokenizer_xxl = AutoTokenizer.from_pretrained(checkpoint_xxl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baf3b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.mem_get_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_memory = {0: \"7GIB\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6087e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xxl = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_xxl, torch_dtype=\"auto\", device_map=\"auto\", cache_dir=CACHE_DIR, offload_folder=OFFLOAD_FOLDER, max_memory=max_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925cee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(\"Translate to English: Je t’aime.\", return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(inputs)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6813cfb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bloom_env",
   "language": "python",
   "name": "bloom_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
